{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from back2back import Back2BackTranslator\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape = (8375, 2)\n",
      "dev_df.shape = (2094, 2)\n",
      "yes_pcl.shape = (794, 2)\n",
      "no_pcl.shape = (7581, 2)\n",
      "proportion_no_over_yes = 9.547858942065492\n",
      "n_yes_val = 238\n",
      "n_no_val = 2274\n",
      "n_validation = 2512\n",
      "n_yes_train = 5004\n",
      "n_no_train = 5307\n",
      "n_train = 10311\n"
     ]
    }
   ],
   "source": [
    "def proprocess_data(validation_proportion=0.3):\n",
    "    # returns 3 dataframes, one for the train set, one for validation set, and one for test\n",
    "    \n",
    "    data_pcl = pd.read_csv(\"./datasets/dontpatronizeme_pcl.tsv\", sep=\"\\t\", skiprows=3,\n",
    "                           names=['par_id','art_id','keyword','country_code','text','label'])\n",
    "    dev_ids = pd.read_csv('./datasets/dev_semeval_parids-labels.csv')\n",
    "    train_ids = pd.read_csv('./datasets/train_semeval_parids-labels.csv')\n",
    "    \n",
    "    # Binary labels\n",
    "    data_pcl['labels'] = data_pcl.label > 1.5\n",
    "    \n",
    "    # Select train and test examples according to train_ids and dev_ids\n",
    "    train_df = data_pcl.loc[data_pcl.par_id.isin(train_ids.par_id)][['text', 'labels']]\n",
    "    dev_df = data_pcl.loc[data_pcl.par_id.isin(dev_ids.par_id)][['text', 'labels']]\n",
    "    \n",
    "    print('train_df.shape =', train_df.shape)\n",
    "    print('dev_df.shape =', dev_df.shape)\n",
    "    \n",
    "    # Is pcl and is not pcl\n",
    "    yes_pcl = train_df.loc[train_df.labels==True]\n",
    "    no_pcl = train_df.loc[train_df.labels==False]\n",
    "    \n",
    "    print('yes_pcl.shape =', yes_pcl.shape)\n",
    "    print('no_pcl.shape =', no_pcl.shape)\n",
    "    print('proportion_no_over_yes =', len(no_pcl) / len(yes_pcl))\n",
    "    \n",
    "    # Seperate train and validation sets randomly with equal proportion of yes-no labels\n",
    "    # for reproducibility:\n",
    "    np.random.seed(1234)\n",
    "    yes_ids = np.random.permutation(len(yes_pcl))\n",
    "    no_ids = np.random.permutation(len(no_pcl))\n",
    "    \n",
    "    n_yes_val = int(validation_proportion * len(yes_pcl))\n",
    "    n_no_val = int(validation_proportion * len(no_pcl))\n",
    "    \n",
    "    n_yes_copies = int( len(no_pcl) / len(yes_pcl) )\n",
    "    \n",
    "    validation_set = pd.concat((yes_pcl.iloc[yes_ids[:n_yes_val]], no_pcl.iloc[no_ids[:n_no_val]]))\n",
    "    train_set = pd.concat((pd.concat((yes_pcl.iloc[yes_ids[n_yes_val:]] for _ in range(n_yes_copies))), no_pcl.iloc[no_ids[n_no_val:]]))\n",
    "    \n",
    "    print('n_yes_val =', (validation_set['labels'] > .5).sum())\n",
    "    print('n_no_val =', (validation_set['labels'] < .5).sum())\n",
    "    print('n_validation =', len(validation_set))\n",
    "    \n",
    "    print('n_yes_train =', (train_set['labels'] > .5).sum())\n",
    "    print('n_no_train =', (train_set['labels'] < .5).sum())\n",
    "    print('n_train =', len(train_set))\n",
    "    \n",
    "    # Shuffle the training set... Eventhough I'm pretty sure it's already done at every epoch when training\n",
    "    train_set = train_set.iloc[np.random.permutation(len(train_set))]\n",
    "    \n",
    "    return train_set, validation_set, dev_df\n",
    "\n",
    "\n",
    "train_set, validation_set, test_set = proprocess_data(validation_proportion=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>And like temporary refugees , they became the ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>Due to cultural factors and the government 's ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Stefanovic said immigrants \" from faraway land...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>The spirit the Rwandese have shown to accommod...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>Minnis told legislators that migrants who are ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>A submission from the Irish Women 's Council o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>The government has agreed to pay pensions to d...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6678</th>\n",
       "      <td>PIE replaces the common law action whereby own...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>Aside from the subdivision for urban poor fami...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>The number of refugees and returnees in Chad ,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10311 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "8406  And like temporary refugees , they became the ...    True\n",
       "6189  Due to cultural factors and the government 's ...   False\n",
       "239   Stefanovic said immigrants \" from faraway land...   False\n",
       "3137  The spirit the Rwandese have shown to accommod...    True\n",
       "2700  Minnis told legislators that migrants who are ...   False\n",
       "...                                                 ...     ...\n",
       "278   A submission from the Irish Women 's Council o...   False\n",
       "333   The government has agreed to pay pensions to d...   False\n",
       "6678  PIE replaces the common law action whereby own...   False\n",
       "3548  Aside from the subdivision for urban poor fami...   False\n",
       "4764  The number of refugees and returnees in Chad ,...   False\n",
       "\n",
       "[10311 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_b2b_translation(dataset, languages):\n",
    "    '''Augment dataset with back 2 back translation'''\n",
    "    b2b = Back2BackTranslator()\n",
    "    list_datasets = [dataset]\n",
    "    for lang in languages:\n",
    "        duplicate = dataset.copy()\n",
    "        duplicate['text'] = duplicate['text'].progress_apply(\n",
    "            lambda txt: b2b.translate_back2back(lang, txt)\n",
    "        )\n",
    "        list_datasets.append(duplicate)\n",
    "    augmented_dataset = pd.concat((list_datasets))\n",
    "    return augmented_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f921ef27c8bd466fa3eb389411635a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5872b9803204533895c8ee9003596d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dcbb5eee314395aae421461e9c8192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90d4ccd1c64348b541c83a79d1ca55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "languages = ('pt', 'fr', 'cn', 'jp')\n",
    "# I'm using 10 examples (too long on my pc) but should be fine with gpu # Remove .iloc[:10]\n",
    "new_train_set = augmentation_b2b_translation(train_set.iloc[:10], languages)\n",
    "#new_train_set = augmentation_b2b_translation(train_set, languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "print(new_train_set.shape) # In my case: 10 datapoints * 5 languages = 50 datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "model_args = ClassificationArgs(\n",
    "    num_train_epochs=2,\n",
    "    no_save=False,\n",
    "    no_cache=False,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluate_during_training=True, \n",
    "    output_dir='./output1',\n",
    "    best_model_dir='./output1/best_model',\n",
    "    max_seq_length=256, #was 128 by default\n",
    "    save_eval_checkpoints=True,\n",
    "    save_model_every_epoch=True,\n",
    "    save_steps=100_000,\n",
    "    evaluate_during_training_verbose=True,\n",
    "    learning_rate=4e-5,\n",
    "    train_batch_size=16, # was 8\n",
    "    logging_steps=2,\n",
    ")\n",
    "model = ClassificationModel(\n",
    "    \"roberta\",\n",
    "    \"roberta-base\",\n",
    "    args=model_args,\n",
    "    use_cuda=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dd2689facf44c29d59c732f00a463a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hubzer/opt/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eded01706805491b92acebdc3cb51f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8c0614fe80460c901a918a6e9f2677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hubzer/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44df941b9a24097bbb327d6665496b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hubzer/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc6e504be9c45f4a80822f7ccfa5cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d817596c2f4f37a3bad9131396f53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " defaultdict(list,\n",
       "             {'global_step': [4, 8],\n",
       "              'train_loss': [0.7654550075531006, 0.5815525054931641],\n",
       "              'mcc': [0.0, 0.0],\n",
       "              'tp': [0, 0],\n",
       "              'tn': [3, 3],\n",
       "              'fp': [0, 0],\n",
       "              'fn': [3, 3],\n",
       "              'auroc': [0.5555555555555556, 0.5555555555555556],\n",
       "              'auprc': [0.5888888888888889, 0.5888888888888889],\n",
       "              'f1': [0.0, 0.0],\n",
       "              'eval_loss': [0.6934757232666016, 0.6939296126365662]}))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on a mini set (cause don't have gpu for this notebook)\n",
    "model.train_model(\n",
    "    new_train_set,\n",
    "    eval_df=validation_set.iloc[[0,1,2,-3,-2,-1]], # Remove iloc for full validation set\n",
    "    show_running_loss=True,\n",
    "    f1=f1_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>mcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>f1</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.765455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.581553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_step  train_loss  mcc  tp  tn  fp  fn     auroc     auprc   f1  \\\n",
       "0            4    0.765455  0.0   0   3   0   3  0.555556  0.588889  0.0   \n",
       "1            8    0.581553  0.0   0   3   0   3  0.555556  0.588889  0.0   \n",
       "\n",
       "   eval_loss  \n",
       "0   0.693476  \n",
       "1   0.693930  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = pd.read_csv('./output1/training_progress_scores.csv')\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
